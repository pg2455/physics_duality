# this is just all the different kernel functions in one place
# useful for later use. 
import numpy as np
import torch
import torch.nn as nn

def moment_difference(o1,o2):
    """
    This computes the difference in moments between o1 and o2
    each of those are tensors whose indices are
    o[batch, which_link]
    """

    # first moment: 
    mom1 = torch.linalg.norm(o1.mean(0)-o2.mean(0))

    # second moments:
    # note the Einstein summation convention just sums over the batch while 
    # keeping the indices labeling the link free. 
    # torch.tril keeps only lower indices (so j < k)
    # finally the last division just divides by the batch size 
    o2_mom2= torch.tril(torch.einsum('ij,ik',o1,o1),diagonal=-1)/o1.shape[0]
    o1_mom2= torch.tril(torch.einsum('ij,ik',o2,o2),diagonal=-1)/o2.shape[0]
    mom2 = torch.linalg.norm(o2_mom2 - o1_mom2)

    #return mom1 + 0*mom2
    return (mom1**2) +(mom2**2)

def kernel_trunc(o1,o2):
    """
    This computes the kernel between o1 and o2
    each of those are tensors whose indices are
    o[batch, which_link]

    It actually adds the first and second moments
    It returns a 2d tensor with indices [batch, batch]
    

    """
    # first moment: 

    mom1 = torch.einsum('ia,ja->ij',o1,o2)

    # second moment
    # we need to compute the two factors
    # probably good to make this into a loop at some point

    factor1 = torch.tril(torch.einsum('ia,ib->iab',o1,o1),diagonal=-1)
    factor2 = torch.tril(torch.einsum('ia,ib->iab',o2,o2),diagonal=-1)
    mom2 = (torch.einsum('iab,jab->ij',factor1,factor2))
    return mom1+mom2

def kernel_dot(o1,o2,sigma=128):
    """ 
    This computes yet a different kernel
    This one is actually a genuine reproducing kernel and so should 
    only be minimized when all moments agree. 
    """
    
    return torch.exp(+torch.einsum('ia,ja->ij',o1,o2)/sigma)
    
def kernel_prod(o1,o2,sigma=128):
    """ Andrea's kernel """
    return (1+o1[:,None,:]*o2[None,...]/sigma).prod(-1)
    
def compute_kernel(diff, SIGMAS):
    """
    Computes similarity using original Gaussian kernel. 
    """
    kern = 0
    sq_diff = (diff ** 2).sum(-1)
    for sigma in SIGMAS:
        kern += torch.exp(-sq_diff / sigma)

    return kern

def kernel_gauss(o1,o2,sigma=128):
    """
    Just does it with the regular kernel
    """
    diff = o1[:, None, :] - o2[None, ...]
    return torch.exp(-(diff ** 2).sum(-1)/sigma)

def kernel_feature(masks,o1,o2,sigma=128):
    # project against the feature map, and then take the average over the symmetry group
    # this incorporates the spatial translational invariance 

    # note that this takes as input the masks which is generated by the generate_masks function above
    # you should use functools.partial to make this have the same form as all of the other kernels. 

    # at the moment sigma does nothing, but we could imagine waiting the higher-order moments with it
    # in some way. 

    """
    features1 = torch.mean(torch.einsum('ijkl,mi',masks,o1),dim=(0,1))
    features2 = torch.mean(torch.einsum('ijkl,mi',masks,o2),dim=(0,1))
    """


    # this iterates over the dimension that is the link variable, taking the product of it only if it enters in the mask
    # it returns a tensor that is  (num_samples * N * N * feature index)
    features1 = torch.prod(o1[:,None,None,None,:] ** masks[None,:],-1)
    features2 = torch.prod(o2[:,None,None,None,:] ** masks[None,:],-1)

    # now take the mean over the spatial directions
    avg_features1 = features1.mean((1,2))
    avg_features2 = features2.mean((1,2))

    # now these are all (num_samples * num_features) -- finally, multiply them together while summing over the features
    kern = torch.einsum('ij,kj',avg_features1,avg_features2)
    return kern


def kernel_prod_batch(o1, o2, sigma=128):
    """For batching the prod kernel."""
    return (1+o1[..., None,:]*o2[:, None,...]/sigma).prod(-1)


def compute_kernel_general(o1, o2, SIGMAS, kernel_fn):
    """
    Computes similarity using kernel.
    Args:
        o1, o2: samples
        SIGMAS: parameters required for kernel_fn
        kernel_fn: kernel function of choice
    """
    kern = 0
    for sigma in SIGMAS:
        kern += kernel_fn(o1, o2, sigma)
    return kern